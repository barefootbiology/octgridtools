---
title: "Working with grids and OCT volumes"
author: "S. Scott Whitmore"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE,
                      message = FALSE)
knitr::opts_knit$set(root.dir = here::here())

setwd(here::here())

library(heyexr)
library(octgridtools)
library(tidyverse)
library(patchwork)
library(broom)

source_dir <- function(.path) {
  list.files(path = .path, 
           pattern = ".R",
           full.names = TRUE) %>%
  purrr::walk(~source(file = .x))
}

source_dir("~/stonelab/packages/octgridtools/R_to_incorporate/")


# Specify the location of an example OCT
data_root <- "~/stonelab/experiments/oct/abca4_ush2a_testing/data/controls/segmentation_v3-8-0_2018-02-05/UI_SF_SPT_000501_001_001_001_ORIGINAL/"

example_vol_file <- paste0(data_root, "UI_SF_SPT_000501_001_001_001_ORIGINAL_OCT_Iowa.VOL")

example_segmentation_file <-paste0(data_root, "UI_SF_SPT_000501_001_001_001_ORIGINAL_Surfaces_Iowa.xml")

example_grid_center_file <-paste0(data_root, "UI_SF_SPT_000501_001_001_001_ORIGINAL_GridCenter_Iowa.xml")


example <- read_oct_files(volume = example_vol_file,
                          segmentation = example_segmentation_file,
                          grid_center = example_grid_center_file)

layer_definition_file <- "~/stonelab/experiments/oct/abca4_ush2a_testing/data/layer_map_3-8-0.xlsx"

layer_definition <- readxl::read_excel(layer_definition_file) %>%
  mutate(layer = factor(layer, levels = layer))
```

# Table of Contents

1. Introduction to optical coherence tomography
    a. Spectral domain OCT: SD-OCT
    b. Swept-source OCT: SS-OCT
    c. Volumetric data (x, y, z): anisotropy
2. Data files
    a. Heidelberg VOL files: metadata + SLO + B-scan metadata + volume data
    b. Carl Zeiss DICOM files: volume data
        i. Volume data
        ii. Volumetric angiography data
3. Segmentation
    a. Heidelberg segmentation
    b. Iowa Reference Algorithms/OCTExplorer
    c. Representing segmentation surfaces and layers in B-Scans, adjusting intensity
    d. Considerations on segmentation quality, manual adjustment of layers
5. Computing on volume data
    a. Using segmentation to slice volumes
    b. Computing en face matrices (images) using sliced volumes
        i. Thickness maps
        ii. Depth maps
        iii. En face structural images
        iv. Combining structure and depth using HSV colors
    c. Overlaying en face images on SLO
6. Statistics and visualization with groups of OCTs
    a. Voxel space and anatomic space: Translation, centering, scaling
    b. Using bins and grids for consistent comparisons
    c. Computing stats across groups of samples
    d. Displaying stats as heatmapped B-scans
7. Projecting data in three dimensions
    a. Surface stacks
    b. Volume sliced with computed or retrieved texture maps
    c. Filtering potentially noisy values for simple segmentation of angio data
    d. Combining angio with volume data
    e. Voxel ray tracing, anyone?
8. Exporting data
    a. For use in Fiji (Fiji Is Just ImageJ)
    b. To view 3D objects using WebGL


# Introduction

Let's walk through the pieces of a Heidelberg VOL file.

* Every file starts with a **header** ...

* After the header comes the **scanning laser ophthalmoscopy (SLO) image.** The 
provides an en face, infrared image of the retina. [TASK: What does the infrared
wavelength reveal?] 

* The remainder of the file is composed of **b-scan headers** and 
**b-scan data**. [TASK: Where does the automatic segmentation appear?]

# Image types

* SLO (x, y)

* Volume data (x, y, z)

* En face images (x, y) computed using segmentation surfaces and the volume data

* B-scans (x, z)

* C-scans (y, z) [I think this is what you call a cross-section through 
b-scans!]

# Scanning laser ophthalmoscopy (SLO) image

Of note, the anatomic superior portion of the image is actually at the bottom of
the dataset. To correct for this, we have reversed the `y` axis scale.

```{r }
p_slo <- heyexr::construct_slo(example$volume, 
                      low_color = "black", 
                      high_color = "white", 
                      scale_bar = FALSE, 
                      scale_length = 200, 
                      inset_percentage = .10, 
                      draw_margins = TRUE)

p_slo
```


# B-scans and segmentation surfaces

B-scans are at the heart of the OCT data. (SLO is captured by the Heidelberg
Spectralis, but isn't the OCT proper.) We can show the position of the b-scans 
on the SLO image.

```{r }
p_slo +
  geom_segment(data = example$volume$bscan_headers,
               mapping = aes(group = bscan,
                             x = start_x_pixels, 
                             y = start_y_pixels,
                             xend = end_x_pixels, 
                             yend = end_y_pixels),
               color = "green", 
               alpha = 0.4) +
  geom_text(data = example$volume$bscan_headers %>%
               filter(bscan %in% seq(from = 1, to = 61, by = 3)),
            mapping = aes(label = bscan,
                          x = start_x_pixels,
                          y = start_y_pixels),
            color = "white", 
            size = 2.5,
            hjust = 0,
            fontface = "bold")

test_bscan_id <- 30
```

# B-scan with segmentation surfaces

Here's what b-scan `r test_bscan_id` looks like with the automatic segmentation
included in the VOL file overlaid:

```{r }
construct_bscan(example$volume, bn = test_bscan_id) +
  geom_line(data = get_segmentation(example$volume) %>% filter(b_scan == 30),
            mapping = aes(x = x, 
                          y = z, 
                          group = surface, 
                          color = surface),
            alpha = 0.75) +
  scale_color_brewer(palette = "Set1") +
  coord_equal()
```

Notice that Heidelberg only includes the NFL surface for radial scans.


# Iowa Reference Algorithms

But we definitely aren't limited to using the Heidelberg segmentation. The
Iowa Reference Algorithms, bundled with OCTExplorer, identifies 11 or 12 
surfaces (10 or 11 layers) depending on the version you are using. Currently,
the heyexr package is designed around OCTExplorer v 3.8.0 output.

TASK: Standardize the layer segmentation coordinates between Heidelberg and
IRA/OCTExplorer (x, y, value, surface_id, etc.).

```{r }
segmentation_ira <- example$segmentation$layers %>% 
              left_join(get_undefined(example$segmentation)) %>%
              inner_join(layer_definition, 
                         by = c("layer_y_order" = "surface")) %>%
  mutate(is_defined = if_else(is.na(is_defined), TRUE, FALSE))

construct_bscan(example$volume, bn = test_bscan_id) +
  geom_line(data = segmentation_ira %>%
              filter(bscan_id == 30),
            mapping = aes(x = ascan_id, 
                          y = value, 
                          group = layer, 
                          color = layer),
            alpha = 0.75) +
  scale_color_brewer(palette = "Paired") +
  coord_equal()
```


***

You'll notice that toward the edges, the segmentation appears wavy. The
IRA can flag specific a-scans as "undefined", identicating that the segmentation
is uncertain in those areas. We can filter the segmentation to remove the 
"undefined" surfaces:

```{r }
construct_bscan(example$volume, bn = test_bscan_id) +
  geom_line(data = segmentation_ira %>%
              filter(bscan_id == 30) %>%
              filter(is_defined),
            mapping = aes(x = ascan_id, 
                          y = value, 
                          group = layer, 
                          color = layer),
            alpha = 0.75) +
  scale_color_brewer(palette = "Paired") +
  coord_equal()
```

# Cross-sections through b-scans

Alternatively, we can construct cross-sections through b-scans, cutting along
the y-axis of the volume.

TASK: Write a `get_cross_section` function. [TASK: What is the technical name
for this slice?]


# En face computed images

We can also compute en face images. For example, here's an en face image 
generated by summing along each a-scan:

```{r }
vol_data <- example$volume$bscan_images 
 
enface_total <- vol_data %>% 
  apply(c(1,2), sum, na.rm = TRUE) %>% 
  reshape2::melt() %>% 
  as_tibble() %>%
  set_names(c("x", "y", "intensity")) 

aspect_ratio <- get_enface_aspect(example$volume)
  
enface_total %>%
  ggplot(aes(x = x, y = y)) +
  geom_raster(aes(fill = intensity)) +
  coord_fixed(ratio = aspect_ratio)
```

Notice that the structural en face image based on the total volume doesn't need 
to be reversed on the y-axis. The bscans are ordered in the VOL file from 
inferior to superior.

# Surface maps

We can create basic surface maps of the segmentation several ways:

```{r }
# The surface map of the ILM
create_seg_array(example$segmentation)[ , , 2] %>% 
  reshape2::melt() %>% 
  as_tibble() %>% 
  set_names(c("x", "y", "z")) %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_raster(aes(fill = z))  +
  coord_fixed(ratio = aspect_ratio)
```


# Total retinal thickness

We can compute total retinal thickness using the segmentation stored in the VOL
file. Alternatively, we can use the segmentation from IRA/OCTExplorer.

```{r }
enface_retinal_thickness_heidelberg <- 
  example$volume$seg_array[, , c(1, 2)] %>% 
  compute_thickness(scale_value = example$volume$header$scale_z * 1000) 

enface_retinal_thickness_octexplorer <- 
  create_seg_array(example$segmentation)[ , , c(2, 12) ] %>%
  compute_thickness(na_undefined = get_undefined(example$segmentation),
                    scale_value = example$segmentation$info$voxel_size_y * 1000) 

enface_retinal_thickness <- 
  bind_rows(
    enface_retinal_thickness_octexplorer %>%
      mutate(algorithm = "Iowa"),
    enface_retinal_thickness_heidelberg %>%
      mutate(algorithm = "Heidelberg")
  )

enface_retinal_thickness %>%
  ggplot(aes(x = x, y = y)) + 
  geom_raster(aes(fill = thickness_scaled)) +
  scale_fill_gradientn(name = "thickness\n(µm)",
                       colours = rainbow(n = 10)) +
  facet_grid(~ algorithm) +
  coord_fixed(ratio = aspect_ratio)


# Notice that missing (NA) values are shown in gray. 
# 
# Note well: The ordering of b-scans from the Heidelberg VOL file and the ordering
# of the IRA/OCTExplorer segmentation XML are opposite. In `heyexr`, I reorder the 
# b-scan IDs for the IRA segmentation to match the Heidelberg VOL order.
```


# Difference maps

We can compare the performance of both retinal thickness measures:

```{r }
enface_retinal_thickness_difference <- enface_retinal_thickness %>% 
  select(x, y, thickness_scaled, algorithm) %>% 
  spread(algorithm, thickness_scaled) %>% 
  mutate(difference = Heidelberg - Iowa) 

p_scatterplot <- enface_retinal_thickness_difference %>%
  ggplot(aes(x = Heidelberg, y = Iowa)) +
  geom_abline(slope = 1, color = "red") +
  geom_point(size = 0.2, alpha = 0.25) +
  coord_equal()

p_difference_map <- enface_retinal_thickness_difference %>%
  ggplot(aes(x = x, y = y)) +
  geom_raster(aes(fill = difference)) +
  scale_fill_gradient2(name = "thickness difference\nHeidelberg - Iowa\n(µm)",
                       low = "blue", mid = "white", high = "red") +
  coord_fixed(ratio = aspect_ratio)

p_difference_map + p_scatterplot + plot_layout(nrow = 1, widths = c(4, 3))
```

# Overlaying en face computed images on the SLO

We can overlay our en face images back onto the SLO image. This kind of overlay 
can be used for any type of array-based, raster-type computation, for example, 
thickness maps, deviations, structural enface images, or depth 
maps.

```{r }
p_thickness_octexplorer_alpha <- enface_retinal_thickness_octexplorer %>%
  ggplot(aes(x = x, y = y)) + 
  geom_raster(aes(fill = thickness_scaled),
              alpha = 0.5) +
  scale_fill_gradientn(name = "thickness\n(µm)",
                       colours = rainbow(n = 10), 
                       na.value = "transparent") +
  # Be sure to remove the extra padding!
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0))

thickness_legend <- get_legend(p_thickness_octexplorer_alpha)

p_slo_overlay <- p_slo + 
  annotation_overlay(plot_overlay = p_thickness_octexplorer_alpha + theme_nude,
                     volume = example$volume) 

gridExtra::grid.arrange(p_slo_overlay, 
                        thickness_legend, 
                        ncol = 2, 
                        widths = c(5, 1))

# I still need to adjust the bounding box to take into account potential 
# rotation of the b-scans (for VOL files exported as unregistered only).
# 
# By default, missing values are coded as a dark gray color by ggplot2. We can
# remove those values by filtering the tibble prior to creating the overlay. 
# However, if an entire row or column of data were missing, that would reduce the
# size of the data in the PNG, meaning we would accidentally stretch the thickness
# values further across the SLO, misrepresenting the data. To bypass this problem,
# set `na.value = "transparent"` in the `scale_fill_*` function.
```

***

Note that the b-scan lines indicate the middle of the voxels:

```{r }
p_slo_overlay_bscans <- p_slo_overlay + 
    geom_segment(data = example$volume$bscan_headers,
               mapping = aes(group = bscan,
                             x = start_x_pixels, 
                             y = start_y_pixels,
                             xend = end_x_pixels, 
                             yend = end_y_pixels),
               color = "green", 
               alpha = 0.4)

gridExtra::grid.arrange(p_slo_overlay_bscans, 
                        thickness_legend, 
                        ncol = 2, 
                        widths = c(5, 1))
```

*** 

We can compute en face images using the voxels between difference 
segmentation surfaces. To do this, we take the segmentation surfaces and 
construct another volume of the same dimensions. We'll use this second volume
as a mask to pull out (slice) voxels from the OCT volume. For example, here is
a b-scan showing the all the layers. Note that the layers start at 0 (between
the top of the scan and the first [ILM] layer) and goes 1 beyond the number of 
surfaces (RPE to base of scan).

```{r }
# 2018-02-19  Monday
# 
# TASK: Make a function that can pull out the voxels between surfaces, as needed
#       for computing structural en face images.
# NOTE: The function needs to handle any segmentation array.

# source("R/create_seg_array.R")

seg_volume <- expand_surfaces_to_volume(
    surface_array = iowa_segmentation_to_array(example$segmentation),
    vol_dim = dim(example$volume$bscan_images)
  )

seg_bscan_layers <- 
  seg_volume[ , 30, ] %>%
  reshape2::melt() %>%
  set_names(c("x", "z", "layer")) %>%
  as_tibble()

seg_bscan_layers_centers <-
  seg_bscan_layers %>%
  group_by(layer) %>%
  summarize(x = median(x), z = median(z))

seg_bscan_layers %>%     
  ggplot(aes(x = x, y = z)) +
  geom_raster(aes(fill = as.factor(layer))) +
  scale_fill_brewer(name = "layer",
                    palette = "Set3") +
  geom_text(data = seg_bscan_layers_centers,
            mapping = aes(x = x, y = z, label = layer),
            fontface = "bold") +
  scale_y_reverse()
```

***

You can then select layer indices by to create slices.

```{r }
surface_array <- iowa_segmentation_to_array(example$segmentation)

slicer_full_thickness <- create_slicer(seg_volume = seg_volume, 1, 10)

slicer_full_thickness[ , 30, ] %>%
  reshape2::melt() %>%
  set_names(c("x", "z", "intensity")) %>%
  as_tibble() %>%
  ggplot(aes(x = x, y = z)) +
  geom_raster(aes(fill = intensity)) +
  scale_y_reverse()
```

***

And here are the voxels it sliced:

```{r }
volume_sliced <- example$volume$bscan_images * slicer_full_thickness

volume_sliced[ , 30, ] %>%
  reshape2::melt() %>%
  set_names(c("x", "z", "intensity")) %>%
  as_tibble() %>%
  mutate(intensity0 = if_else(is.na(intensity), 
                             0,
                             intensity)) %>%
  mutate(intensity0 = heyexr::spline_correction(intensity0)) %>%
  mutate(intensity = if_else(is.na(intensity), 
                             as.numeric(NA),
                             intensity0)) %>%
  ggplot(aes(x = x, y = z)) +
  geom_raster(aes(fill = intensity)) +
  scale_y_reverse()
```

***

Once we have sliced voxels, we can now compute statistics for every a-scan to
compute a new en face image:

```{r }
p_enface_full_thickness <- volume_sliced %>%
  spline_correction_array() %>%
  apply(c(1,2), sum, na.rm = TRUE) %>%
  reshape2::melt() %>%
  set_names(c("x", "y", "value")) %>%
  as_tibble() %>%
  full_join(get_undefined(example$segmentation)) %>%
  mutate(is_defined = if_else(is.na(is_defined), TRUE, is_defined)) %>%
  mutate(value = if_else(is_defined, value, as.numeric(NA))) %>%
  
  ggplot(aes(x = x, y = y)) +
  geom_raster(aes(fill = value),
              alpha = 1) +
  scale_fill_gradient(low = "blue", high = "red") +
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0))  

p_slo_overlay_enface <- p_slo + 
  annotation_overlay(plot_overlay = p_enface_full_thickness + theme_nude,
                     volume = example$volume) 

p_slo_overlay_enface
```

***

Alternatively, we can compute other kinds of representations using slicers.
For example, we can compute the median intensity within a layer, then 
show color the layer by that intensity:

```{r }
volume_median <- apply_volume(
  volume = spline_correction_array(example$volume$bscan_images), 
  seg_volume = seg_volume,
  .fun = median,
  na.rm = TRUE
  )

volume_median[ , 30, ] %>%
  reshape2::melt() %>%
  set_names(c("x", "z", "intensity")) %>%
  as_tibble() %>%
  ggplot(aes(x = x, y = z)) +
  geom_raster(aes(fill = intensity)) +
  scale_y_reverse() +
  scale_fill_gradient(guide = "none",
                      low = "black", 
                      high = "white", 
                      limits = c(0, 1))
```

***

Contrast that image with the standard deviation:

```{r }
volume_sd <- apply_volume(
  volume = spline_correction_array(example$volume$bscan_images), 
  seg_volume = seg_volume,
  .fun = sd,
  na.rm = TRUE
  )

volume_sd[ , 30, ] %>%
  reshape2::melt() %>%
  set_names(c("x", "z", "intensity")) %>%
  as_tibble() %>%
  ggplot(aes(x = x, y = z)) +
  geom_raster(aes(fill = intensity)) +
  scale_y_reverse() +
  scale_fill_gradient(low = "black", 
                      high = "white")
```

Notice that here, to emphasize the relative differences between layers, we've
adjusted the color scale.

***

We can also compute other functions across the regions and return a list of 
objects (instead of returning another volume). For example, we can show the 
distribution of intensities in each layer:

```{r }

layer_intensity_values <- map_volume(
  volume = spline_correction_array(example$volume$bscan_images),
  seg_volume = seg_volume,
  .fun = c,
  na.rm = TRUE
  )  %>%
  map_dfr(~tibble(intensity = .x),
          .id = "layer_id") %>%
  mutate(layer_id = as.factor(as.numeric(layer_id))) %>%
  filter(layer_id %in% as.character(1:10)) 

# layer_intensity_values %>%
#   ggplot(aes(x = layer_id, y = intensity)) +
#   geom_boxplot(aes(fill = layer_id)) +
#   scale_fill_brewer(palette = "Paired") +
#   coord_flip() 

layer_intensity_values %>%
  ggplot(aes(x = intensity)) +
  geom_density(aes(fill = layer_id)) +
  scale_fill_brewer(palette = "Paired") +
  facet_grid(layer_id ~ .)
```

TASK: Re-work the enface related functions to be something like 
`apply_volume_enface`. (Perhaps we should rename the `apply_volume` function
to be `apply_volume_volume`, indicating that you are returning a volume.) OR 
possibly use `apply_volume_xyz`, `apply_volume_xy`, etc.

TASK: Write a function to merge the `undefined` values into the layer tibble.
Then replace the redundant code throughout this document.

TASK: Write functions to work summary statistics in 3D grids.

TASK: Expand sections to illustrate how the concepts presented here can be 
generalized to groups of samples. For example, you can compute statistics across
multiple samples in a control group, then show how a given sample compares to 
the controls. You can create heatmaps as well.

# Flattening segmentation: Surfaces

Segmentations can be effectively flattened in order to normalize the curvature
to one of the surfaces. For example, sometimes it's desireable to flatten the
layer representation by subtracting out the base of the RPE:

```{r }
layers_flattened <- example$segmentation$layers %>% 
  full_join(get_undefined(example$segmentation)) %>%
  mutate(is_defined = if_else(is.na(is_defined), TRUE, is_defined)) %>%
  mutate(value = if_else(is_defined, value, as.numeric(NA))) %>%
  filter(bscan_id == 30) %>%
  group_by(bscan_id, ascan_id) %>% 
  mutate(value_flattened = max(value) - value) %>%
  ungroup() 

layers_flattened %>% 
  filter(bscan_id == 30) %>% 
  ggplot(aes(x = ascan_id, y = value_flattened)) + 
  geom_line(aes(group = layer_y_order, 
                color = as.factor(layer_y_order))) +
  scale_color_brewer(palette = "Paired")
```

Assuming you have good quality segmentation for a set of OCT images, you can
compute averages as well.

TASK: Show average control profiles here.

# Flattening segmentation: Layers

We can easily represent the layers as well. We'll plot from the top 
of surface to the baseline. As long as the layers are ordered from ILM to RPE,
they won't overplot each other:

```{r }
layers_flattened %>% 
  filter(bscan_id == 30) %>% 
  ggplot(aes(x = ascan_id, y = value_flattened)) + 
  geom_line(aes(group = layer_y_order, 
                color = as.factor(layer_y_order))) +  
  geom_ribbon(aes(group = layer_y_order, 
                  ymax = value_flattened,
                  ymin = 0,
                fill = as.factor(layer_y_order))) +
  scale_fill_brewer(palette = "Paired") +
  scale_color_brewer(palette = "Paired")
```

***

TASK: Create a function out of the following code:

```{r }
grid_file <- system.file("extdata", "Grid_Circle_Macula_ETDRS.txt", 
                         package = "octgridtools")

etdrs_grid <- generate_grid_sectors(read_tsv(grid_file), 0, 0)

etdrs_grid %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_polygon(aes(group = .cell_id), 
               fill = NA, 
               color = "red") +
  geom_text(data = etdrs_grid %>% 
              group_by(.cell_id) %>% 
              summarize(x = mean(x), y = mean(y)), 
            mapping = aes(label = .cell_id)) + 
  coord_equal()
```

# Slicing in detail

Remember the Presto Salad Shooter from the '90s? That's what slicers do: slice
up an array into pieces that you can then work with.

## What are slicers?

A slicer is a special arrays used to apply some function to subsets of elements
within another array. In image analysis terminology, slicers are used to 
**segment** a dataset into discrete sets.

## How can you construct slicers?

* From segmentation surfaces

* From regular grids

* By combining two or more slicers, you can create a new slicers

* By specifying formulas, such as multidimensional transfer functions. When
rendering CT data using ray casting, 3D transfer functions have been used to
segment out different tissue types based on distributions of various 
parameters. We can potentially do the same for OCTs.

Many slicers will conceptually have two components:

* The general [component] will apply to all volumes. For instance, the layers
of a retinal layer segmentation algorithm will apply to all macular OCTs (even
if a layer is absent in a particular OCT volume).

* However, the coordinates will be specific to a given volume. For instance,
if a grid is to be centered on the fovea, then the voxels (elements) specifying
the slicer must be specified for each OCT image volume.

On the other hand, if the data arrays are registered between scans (for example,
so that all the volumes share the save fovea coordinate), then the same slicer
could be applied to all volumes.

## Applying a function to volume using a slicer

I've written two functions to apply slicers to volumes:

* `apply_volume` takes a volume, a slicer, and function and returns a volume.

* `map_volume` takes a volume, a slicer, and function and returns a list.

## Working with multiple volumes

Considersations:

* Are the volumes you are slicing all registered? In other words, can you apply
the same slicer to all the volumes or will the slicer need to be aligned for
each volume individually?

* Make sure that your grid regions are larger than the least-dense volume. 
With grids/slicers, you are trying to aggregate across voxels to overcome 
differences in the resolution of the captured data.


## Combining slicers into new slicers

Slicers can be combined if they have the same dimensions. For character array
slicers, this will take a the form of pasting the slicer levels together with
some separation value.

NOTE: At this point, string slicers are not associated with factor "levels".
Any ordering of slicer values or mapping to some other information must be
performed by the user.

TASK: Should we allow for the case where one slicer is 2D and one is 3D?
For simplicity, probably not.

**TASK: Notice that the volume representation and the SLO representation are 
flipped along the horizontal axis. That is 9 --> 7 and 3 --> 5. Fix this to 
match the OCTExplorer interpretation.**

Here's the ETDRS grid shown in voxel space:

```{r }
grid_slicer <- convert_grid_to_slicer(
  grid = etdrs_grid, 
  grid_center = example$grid_center, 
  dims = dim(example$volume$bscan_images), 
  scale_x = example$volume$header$scale_x,
  scale_y = example$volume$header$distance
  )

p_slo <- heyexr::construct_slo(example$volume, 
                      low_color = "black", 
                      high_color = "white", 
                      scale_bar = FALSE, 
                      scale_length = 200, 
                      inset_percentage = .10, 
                      draw_margins = TRUE)

p_overlay <- grid_slicer[ , , 1] %>% 
  reshape2::melt() %>% 
  set_names(c("x", "y", ".cell_id")) %>% 
  as_tibble() %>% 
  ggplot(aes(x = x, y = y)) + 
  geom_raster(aes(fill = as.factor(.cell_id)),
              alpha = 0.7) +   
  scale_x_continuous(expand = c(0,0)) + 
  scale_y_continuous(expand = c(0,0)) +
  scale_fill_brewer(palette = "Set1")

p_overlay
```

Here's what the ETDRS grid looks like en face in the SLO space:

```{r }
slo_center <- get_slo_center(example$volume, example$grid_center)

grid_mm <- 
  etdrs_grid %>% 
  mutate(x = (x / example$volume$header$scale_x_slo) + slo_center[["x"]],
         y = (y / example$volume$header$scale_y_slo) + slo_center[["y"]])

grid_mm_labels <-
  grid_mm %>%
  group_by(.cell_id) %>%
  dplyr::summarize(x = mean(x),
            y = mean(y)) %>%
  ungroup()

p_slo + 
  geom_segment(data = example$volume$bscan_headers,
             mapping = aes(group = bscan,
                           x = start_x_pixels, 
                           y = start_y_pixels,
                           xend = end_x_pixels, 
                           yend = end_y_pixels),
             color = "green", 
             alpha = 0.4) +
  annotation_overlay(p_overlay + theme_nude, volume = example$volume) + 
  geom_polygon(data = grid_mm,
               mapping = aes(x = x, y = y, group = .cell_id),
               fill = NA, 
               color = "blue",
               alpha = 0.5) +
  geom_text(data = grid_mm_labels,
             mapping = aes(x = x, y = y, label = .cell_id),
             size = 4,
             fontface = "bold")
```

TASK: Add a plot showing all the voxels within a particular ETDRS grid for a 
specific layer. You might want to do this in order to inspect just how well
the segmentations are working for a partiular layer in a particular grid region,
especially if you want to compute some kind of statistics on that set of voxels,
(for example, the standard deviation of the intensity). In other words, show a
crop of each b-scan as a wrapped facet, then show only the voxels in that layer
regions.

TASK: Write a section describing how you can "colorize" voxels by using HSV 
values. In other words, we can color the voxels in a layer based on some color
component and intensity, etc.

TASK: Write a function to predict which voxels in a 12x12 mm grid are actually
noise based on the data in a 6x6 grid.

Compute the en face images for each segmentation surface:

```{r }
source_dir("~/stonelab/packages/octgridtools/R_to_incorporate/")

undefined_matrix <- get_undefined_matrix(example$segmentation)

surfaces_enface <- 
  example$volume$bscan_images %>%
  spline_correction_array() %>%
  map_volume_xy( 
    seg_volume = seg_volume, 
    (function(x) { apply(X = x, c(1,2), sum, na.rm = TRUE)})
    ) %>%
  # Remove the unreliable A-scans
  map(~.x * undefined_matrix) %>%
  # Normalize the en face values within each layer
  map(normalize_matrix) %>%
  # Pull out the ILM - RPE
  (function(x) x[2:length(x)])

surfaces_enface[["2"]] %>%
  image()
```

These are the en face images for all the surfaces:

```{r }
surfaces_enface %>%
  map_dfr(~reshape2::melt(), 
          .id = "layer") %>%
  ggplot(aes(x = x, y = y)) +
  geom_raster(aes(fill = value)) +
  facet_wrap(~layer, ncol = 4)
```

Thicker surfaces tend to result in high en face sums. When plotting, it's
often better to normalize the values within each surface to better captuer the
dynamic range within a layer.

```{r }
surfaces_enface %>%
  map_dfr(~reshape2::melt(), 
          .id = "layer") %>%
  group_by() %>%
  dplyr::mutate(value = scales::rescale(value, to = c(0, 1))) %>%
  ungroup() %>%
  ggplot(aes(x = x, y = y)) +
  geom_raster(aes(fill = value)) +
  facet_wrap(~layer, ncol = 4)
```

Plot each segmentation surface in 3D:

```{r }
library(rgl)

surface_array_list <- 
  create_seg_array(example$segmentation) %>%
  split_xyz_by_z() %>%
  # Omit the artificial top and bottom surfaces
  (function(x) x[2:12]) 

surface_colors <- RColorBrewer::brewer.pal(11, "Paired")

volume_center <- get_array_center(example$volume$bscan_images)

# Rotate the camera
rotation_matrix <- rotationMatrix(2 * pi * 125/360, 1, 0, 0) %*%
         rotationMatrix(2 * pi * 140/360, 0, 0, 1)

# Show the bounding box as a wireframe cube
volume_boundaries <- cube3d() %>%
  scale3d(x = dim(example$volume$bscan_images)[[1]] / 2,
          y = dim(example$volume$bscan_images)[[2]] / 2,
          z = dim(example$volume$bscan_images)[[3]] / 2) %>%
  translate3d(x = volume_center[[1]],
              y = volume_center[[2]],
              z = volume_center[[3]]) 

# Assemble the pieces of the plot ----------------------------------------------
setup_plot3d <- function() {
  rgl.open(useNULL = rgl.useNULL()) 
  
  # Set aspect ratio
  # NOTE: Aspect ratios will need to be adjusted if you use SS-OCT data
  aspect3d(x = 1, y = aspect_ratio, z = 1)
  
  view3d(userMatrix = rotation_matrix)
  
  volume_boundaries %>%
    wire3d()
}
```

Once again, we have another coordinate space to consider. In order to position
the surface map properly, we need to flip the segmentation array--and any other
values aligned to that array, such as texturemaps--along the `y` axis.

```{r }
setup_plot3d()

surface_array_list %>%
  iwalk(~surface3d(x = 1:example$segmentation$info$size_x,
                 y = 1:example$segmentation$info$size_z,
                 z = flip_array(.x, 2), 
                 color = surface_colors[as.numeric(.y)],
                 add = TRUE))
rglwidget()
```

Even though we have discarded undefined A-scans in the data matrix, both 
`rgl::persp3d` and  `rgl::surface3d` will still interpolate the surfaces at 
those positions. Thus, we need some way to highlight positions on the surface as 
undefined. This highlighting can be done by creating a special lookup table for 
the en face structural color map.

```{r }
gray_scale <- 
  map(0:255 / 255, gray) %>% 
  as_vector() %>%
  # Add a color for the NA value
  c("green")

surface_enface_colors <- 
  surfaces_enface %>%
  map(~255 * flip_array(.x, 2) + 1) %>%
  map(~na_replace(.x, 257))  %>%
  map(~gray_scale[.x])

setup_plot3d()

surface_array_list %>%
  (function(x) set_names(x, as.character(1:length(x)))) %>%
  iwalk(~surface3d(x = 1:example$segmentation$info$size_x,
                 y = 1:example$segmentation$info$size_z,
                 z = flip_array(.x, 2), 
                 color = surface_enface_colors[[.y]],
                 add = TRUE))

rglwidget()
```

Alternatively, we could set the alpha to 0 for undefined A-scans. However, `rgl`
becomes horribly slow when alphas are used. The code is below, but we won't
render it.

TASK: Set alpha to 0 to "remove" the undefined A-scans.

```{r }
surface_enface_alphas <- 
  surface_enface_colors %>%
  map(~if_else(.x == "green", 0, 1))

setup_plot3d()

surface_array_list %>%
  (function(x) set_names(x, as.character(1:length(x)))) %>%
  iwalk(~surface3d(x = 1:example$segmentation$info$size_x,
                 y = 1:example$segmentation$info$size_z,
                 z = flip_array(.x, 2), 
                 color = surface_enface_colors[[.y]],
                 alpha = surface_enface_alphas[[.y]],
                 add = TRUE))

rglwidget()

```

It would be nice to cut away the layers so that we can see the en face 
representation of lower layers. We can start this cut away at the fovea.

```{r }


```


# Future tasks

* TASK: ~~Store bscans as a single 3D array--it will make your life much easier!~~ 
DONE!

* TASK: ~~Store segmentations as a single 3D array.~~ DONE!

* TASK: ~~Re-order either to VOL bscan IDs or the IRA/OCTExplorer b-scan IDs so that
they match correctly.~~ DONE!

* TASK: ~~Add a function to heyexr to render structural en face image from the
volume data.~~ DONE!

* TASK: Update all functions dependent on bscan_images

* TASK: Intensity in the SLO should not be z! Change z to intensity.

* TASK: Convert all coordinate systems to either Heidelberg coordinates or 
OCTExplorer coordinates.

* TASK: Replace data.frames with tibbles.

* TASK: Create a figure showing the cone/rod/ganglion cell densities computed 
by Christine Curcio overlaid on B-scans. I think this will let us highlight the
"central cone bouquet"
